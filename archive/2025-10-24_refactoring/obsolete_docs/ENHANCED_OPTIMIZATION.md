# Enhanced Hyperparameter Optimization

## Overview
Improved hyperparameter optimization now covers ALL four classifiers with cost-sensitive learning integrated into the optimization process.

## What Changed

### 1. Configuration (`config.m`)

**Before:**
- Only SVM and Random Forest optimized
- 20 optimization iterations
- Limited parameter ranges

**After:**
- ‚úÖ All 4 classifiers optimized (LDA, PLS-DA, SVM, Random Forest)
- ‚úÖ 30 optimization iterations (more thorough search)
- ‚úÖ Configurable parameter ranges for each classifier
- ‚úÖ Cost-sensitive learning integrated into optimization

### 2. Optimization Functions (`run_patientwise_cv_direct.m`)

#### LDA Optimization
- **Parameters**: Delta (regularization for covariance), Gamma (regularization for quadratic term)
- **Method**: Bayesian optimization with MATLAB's built-in `OptimizeHyperparameters`
- **Cost-Sensitive**: Uses weighted class priors during optimization
- **Range**: Delta ‚àà [0, 1], Gamma ‚àà [0, 1]

#### PLS-DA Optimization
- **Parameters**: Number of latent components
- **Method**: Grid search with k-fold cross-validation
- **Range**: 1-15 components (configurable via `cfg.optimization.plsda_components`)
- **Enhancement**: Better error handling for failed regressions

#### SVM Optimization
- **Parameters**: BoxConstraint (C), KernelScale (gamma for RBF kernel)
- **Method**: Bayesian optimization
- **Cost-Sensitive**: Uses cost matrix `[0, 1; penalty, 0]` during optimization
- **Range**: BoxConstraint ‚àà [0.1, 100], KernelScale ‚àà [0.001, 10]

#### Random Forest Optimization
- **Parameters**: NumTrees, MinLeafSize
- **Method**: Bayesian optimization via `fitcensemble`
- **Range**: NumTrees ‚àà [50, 500], MinLeafSize ‚àà [1, 50]
- **Note**: Cost-sensitive learning applied via sample weights during actual training

## Configuration Parameters

```matlab
% In config.m

% Enable optimization for all classifiers
cfg.optimization.enabled = true;
cfg.optimization.mode = 'all';  % Changed from 'selective'
cfg.optimization.classifiers_to_optimize = {'LDA', 'PLSDA', 'SVM', 'RandomForest'};
cfg.optimization.max_evaluations = 30;  % Increased from 20

% New: Parameter ranges for each classifier
cfg.optimization.lda_delta_range = [0, 1];
cfg.optimization.lda_gamma_range = [0, 1];
cfg.optimization.plsda_components = 1:15;
cfg.optimization.svm_box_range = [0.1, 100];
cfg.optimization.svm_kernel_range = [0.001, 10];
cfg.optimization.rf_trees = [50, 500];
cfg.optimization.rf_leaf_size = [1, 50];
```

## Cost-Sensitive Integration

The key improvement is that **cost-sensitive learning is now integrated into the optimization process**:

| Classifier | Cost-Sensitive Method | Applied During Optimization? |
|------------|----------------------|----------------------------|
| LDA | Weighted priors | ‚úÖ Yes |
| PLS-DA | Stored in model | N/A (regression) |
| SVM | Cost matrix | ‚úÖ Yes |
| Random Forest | Sample weights | During training only |

This means:
- Hyperparameters are optimized **while respecting the cost structure**
- The optimization objective considers the penalty for missing WHO-3
- Better parameter selection for clinical applications

## Expected Performance Improvement

### Before (Default Parameters):
- LDA: ~65-70% accuracy
- PLS-DA: ~75-80% accuracy  
- SVM: ~80-85% accuracy (default C=1, auto kernel scale)
- Random Forest: ~80-85% accuracy (default 100 trees)

### After (Optimized Parameters with Cost-Sensitive Learning):
- LDA: ~70-75% accuracy (optimized Delta/Gamma, cost-aware priors)
- PLS-DA: ~80-85% accuracy (optimal # components)
- **SVM: ~90% accuracy** (optimal C & gamma with cost matrix) ‚≠ê
- **Random Forest: ~90% accuracy** (optimal trees & leaf size) ‚≠ê

### WHO-3 Detection (Most Important):
- **Baseline**: 70-75%
- **Cost-Sensitive Only**: 85-90%
- **Cost-Sensitive + Optimized Parameters**: **90-95% expected** üéØ

## Usage

### Run with Full Optimization:

```matlab
% Load config with all optimizations enabled
cfg = config();

% Load data
data = load_data_direct(cfg);

% Run cross-validation (will optimize all classifiers)
cv_results = run_patientwise_cv_direct(data, cfg);

% Test best classifier
results = evaluate_test_set_direct(data, cfg, cv_results.best_classifier);
```

### Customize Optimization:

```matlab
cfg = config();

% Only optimize specific classifiers
cfg.optimization.classifiers_to_optimize = {'SVM', 'RandomForest'};

% Use fewer iterations for faster testing
cfg.optimization.max_evaluations = 15;

% Adjust PLS-DA component range
cfg.optimization.plsda_components = 1:10;  % Test 1-10 instead of 1-15

data = load_data_direct(cfg);
cv_results = run_patientwise_cv_direct(data, cfg);
```

### Disable Optimization:

```matlab
cfg = config();
cfg.optimization.enabled = false;

% Will use default parameters from config
data = load_data_direct(cfg);
results = evaluate_test_set_direct(data, cfg, 'SVM');
```

## Computational Cost

| Classifier | Optimization Time (Approx.) | Speedup Options |
|------------|----------------------------|----------------|
| LDA | ~2-5 min | Reduce max_evaluations |
| PLS-DA | ~5-10 min | Reduce component range |
| SVM | ~10-20 min | Use parallel=true, reduce evaluations |
| Random Forest | ~10-20 min | Use parallel=true |

**Total Pipeline Time with Full Optimization**: ~30-60 minutes

**Recommendations:**
- Use parallel processing (`cfg.optimization.use_parallel = true`)
- Start with 15-20 evaluations for testing
- Use 30+ evaluations for final/publication runs
- Optimize only critical classifiers during development

## Comparison: Before vs After

### Configuration Complexity
- **Before**: Simple, only 2 classifiers optimized
- **After**: Comprehensive, all classifiers with detailed control

### Performance
- **Before**: Good baseline, some classifiers underperforming
- **After**: All classifiers near-optimal, better WHO-3 detection

### Flexibility
- **Before**: Limited parameter control
- **After**: Full control over optimization ranges and methods

### Clinical Relevance
- **Before**: Cost-sensitive learning separate from optimization
- **After**: Cost-sensitive learning integrated - parameters optimized for clinical goal

## Technical Details

### Bayesian Optimization (LDA, SVM, Random Forest)
- Uses Gaussian process models to predict performance
- Balances exploration (trying new areas) vs exploitation (refining best areas)
- More efficient than grid search for continuous parameters
- Typically finds good parameters in 20-30 evaluations

### Grid Search (PLS-DA)
- Tests all values in specified range
- Reliable for single discrete parameter
- Cross-validates each value
- Reports best component count with CV error

### Inner Cross-Validation
- 3-fold CV used during optimization (faster)
- Prevents overfitting to training data
- Balances speed vs accuracy

## Troubleshooting

### "Optimization taking too long"
- Reduce `cfg.optimization.max_evaluations` to 15
- Set `cfg.optimization.use_parallel = false` if causing issues
- Reduce `cfg.optimization.kfold_inner` to 2

### "Optimization failing for specific classifier"
- Check warning messages
- Verify data has no NaN/Inf values
- Ensure sufficient samples for CV
- Try disabling that classifier temporarily

### "Results not improving"
- Default parameters may already be near-optimal
- Try different optimization ranges
- Check if cost penalty needs adjustment
- Consider data quality issues

## Future Enhancements

Potential improvements:
1. **Ensemble optimization**: Optimize combinations of classifiers
2. **Multi-objective optimization**: Balance accuracy vs WHO-3 detection explicitly
3. **Transfer learning**: Use optimization results from similar datasets
4. **Adaptive ranges**: Automatically adjust search ranges based on initial results

---

**Status**: ‚úÖ Complete and Tested  
**Version**: 2.0 (Enhanced Optimization)  
**Date**: October 2025
